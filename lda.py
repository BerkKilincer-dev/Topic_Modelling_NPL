# -*- coding: utf-8 -*-
"""LDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n-eZuNO3T8pjgRf9YKcY5T_oGSBRneKk
"""

!pip install gensim
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
import gensim
import gensim.corpora as corpora

"""**LOAD** **DATA**"""

data =pd.read_csv("news_articles (1).csv")

data.head()

data.info()

"""**CLEAN DATA**"""

articles = data['content'].str.lower().apply(lambda x: re.sub(r"([^\w\s])", "", x))

import nltk
nltk.download('stopwords')
en_stopwords = stopwords.words('english')
articles = articles.apply(lambda x: ' '.join([word for word in x.split() if word not in (en_stopwords)]))

import nltk
nltk.download('punkt_tab')
articles = articles.apply(lambda x: word_tokenize(x))

ps = PorterStemmer()
articles = articles.apply(lambda tokens: [ps.stem(token) for token in tokens])

articles

"""**Vectorization**"""

dictionary = corpora.Dictionary(articles) # Her benzersiz kelimeye bir ID verir (Örn: "apple" -> 1).
doc_term = [dictionary.doc2bow(text) for text in articles] # Kelimeleri "Bag-of-Words" formatına sokar.

print(doc_term)

"""**LDA Modelinin Kurulması ve Eğitilmesi**"""

num_topics = 2 # Veride 2 farklı ana konu olduğunu varsayıyoruz.

lda_model = gensim.models.LdaModel(corpus=doc_term,
                                   id2word=dictionary,
                                   num_topics=num_topics)

"""**LDA**"""

# specify number of topics
num_topics = 2

# create LDA model
lda_model = gensim.models.LdaModel(corpus=doc_term,
                                   id2word=dictionary,
                                   num_topics=num_topics)

lda_model.print_topics(num_topics=num_topics, num_words=5)

